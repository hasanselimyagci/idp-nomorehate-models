{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mg9fQvyyEL4f"
      },
      "outputs": [],
      "source": [
        "pip install torch transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.nn.functional import softmax\n",
        "\n",
        "PRETRAINED_LM = 'selimyagci/bert-misogyny-english' # if the model already in HuggingFace hub\n",
        "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_LM) # or like 'google-bert/bert-base-uncased'\n",
        "model = AutoModelForSequenceClassification.from_pretrained(PRETRAINED_LM)\n",
        "# if you are loading the model locally comment above line and use the below\n",
        "# model = torch.load(PATH, map_location=torch.device('cpu'))"
      ],
      "metadata": {
        "id": "C30tNHYuEqo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(text):\n",
        "  input = tokenizer(text, return_tensors='pt')\n",
        "  logits = model(**input).logits\n",
        "  predicted_class_id = logits.argmax().item()\n",
        "  from torch.nn.functional import softmax\n",
        "  probability = (softmax(logits)).data[0][1].item()\n",
        "  s = round(probability,2)\n",
        "  return s # or you can return predicted_class_id, whereas probability returns a value between 0 and 1"
      ],
      "metadata": {
        "id": "YmYzIK0h3EcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(inference('put your text to detect here'))"
      ],
      "metadata": {
        "id": "uAexsR2qbR0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import numpy as np\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def encode(docs):\n",
        "  encoded_dict = tokenizer.batch_encode_plus(docs, add_special_tokens=True, max_length=128, padding='max_length', return_attention_mask=True, truncation=True, return_tensors='pt')\n",
        "  input_ids = encoded_dict['input_ids']\n",
        "  attention_masks = encoded_dict['attention_mask']\n",
        "  return input_ids, attention_masks\n",
        "\n",
        "def evaluateOnTest(PATH):\n",
        "  test = pd.read_csv(PATH)\n",
        "\n",
        "  test_input_ids, test_att_masks = encode(test['text'].values.tolist())\n",
        "  test_y = torch.LongTensor(test['label'].values.tolist())\n",
        "\n",
        "  test_dataset = TensorDataset(test_input_ids, test_att_masks, test_y)\n",
        "  test_sampler = SequentialSampler(test_dataset)\n",
        "  test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model.to(device)\n",
        "\n",
        "  model.eval()\n",
        "  test_pred = []\n",
        "  test_loss= 0\n",
        "  with torch.no_grad():\n",
        "      for step_num, batch_data in tqdm(enumerate(test_dataloader)):\n",
        "          input_ids, att_mask, labels = [data.to(device) for data in batch_data]\n",
        "          output = model(input_ids = input_ids, attention_mask=att_mask, labels= labels)\n",
        "\n",
        "          loss = output.loss\n",
        "          test_loss += loss.item()\n",
        "\n",
        "          test_pred.append(np.argmax(output.logits.cpu().detach().numpy(),axis=-1))\n",
        "  test_pred = np.concatenate(test_pred)\n",
        "\n",
        "  return classification_report(test_pred, test['label'].to_numpy(),target_names=['nothate','hate'])"
      ],
      "metadata": {
        "id": "rGKo9ZCLuL0j"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluateOnTest('putYourTestDataPath')) # run this to get the evaluation report for your test data"
      ],
      "metadata": {
        "id": "4HKCTRS6bsuY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}